{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notbook show an example the uilization of TRAILDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from dataloader import TRAILDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset loaded\n",
      "['Total Load', 'Hour', 'Lockdown']\n",
      "test dataset loaded\n",
      "\n",
      " ground_truth denormalized: \n",
      " tensor([[9417.8496, 9296.7695, 9185.7002, 9091.4795],\n",
      "        [9296.7695, 9185.7002, 9091.4795, 9020.4404],\n",
      "        [9185.7002, 9091.4795, 9020.4404, 8949.7803],\n",
      "        [9091.4795, 9020.4404, 8949.7803, 8857.5400],\n",
      "        [9020.4404, 8949.7803, 8857.5400, 8754.0996],\n",
      "        [8949.7803, 8857.5400, 8754.0996, 8707.9102],\n",
      "        [8857.5400, 8754.0996, 8707.9102, 8650.5400],\n",
      "        [8754.0996, 8707.9102, 8650.5400, 8590.8496]])\n",
      "\n",
      " ground_truth denormalized: \n",
      " tensor([[7846.7798, 7744.1099, 7650.9702, 7605.7397],\n",
      "        [7744.1099, 7650.9702, 7605.7397, 7462.3501],\n",
      "        [7650.9702, 7605.7397, 7462.3501, 7388.3799],\n",
      "        [7605.7397, 7462.3501, 7388.3799, 7427.4399],\n",
      "        [7462.3501, 7388.3799, 7427.4399, 7407.4399],\n",
      "        [7388.3799, 7427.4399, 7407.4399, 7348.5400],\n",
      "        [7427.4399, 7407.4399, 7348.5400, 7377.3901],\n",
      "        [7407.4399, 7348.5400, 7377.3901, 7284.9800]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schmitt/Documents/Trail/dataloader.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data[self.column_to_normalize] = scaled_rows\n",
      "/home/schmitt/Documents/Trail/dataloader.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data[self.column_to_predict] = scaled_row\n",
      "/home/schmitt/Documents/Trail/dataloader.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data[self.column_to_normalize] = scaled_rows\n",
      "/home/schmitt/Documents/Trail/dataloader.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data[self.column_to_predict] = scaled_row\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "csv_file = \"Processed_data.csv\"  # Replace with your CSV file path\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "df_train = df[df[\"Year\"] == 2017]\n",
    "df_test = df[df[\"Year\"] == 2018]\n",
    "\n",
    "\n",
    "input_size = 5\n",
    "columns_input = [\"Total Load\", \"Hour\", \"Lockdown\"]  # Replace with your columns of interest\n",
    "column_to_predict = \"Total Load\"\n",
    "column_to_normalize = [\"Total Load\", \"Hour\", \"Lockdown\"]\n",
    "\n",
    "# Create dataset\n",
    "train_dataset = TRAILDataset(df_train, input_size, columns_input, column_to_predict, column_to_normalize)\n",
    "scaler = train_dataset.get_scaler()\n",
    "predict_scaler = train_dataset.get_predict_scaler()\n",
    "print(\"train dataset loaded\")\n",
    "print(column_to_normalize)\n",
    "test_dataset = TRAILDataset(df_test, input_size, columns_input, column_to_predict, column_to_normalize, scaler=scaler, predict_scaler=predict_scaler)\n",
    "print(\"test dataset loaded\")\n",
    "\n",
    "# Create d\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Example of iterating over the DataLoader\n",
    "for batch in train_loader:\n",
    "    input, ground_truth = batch\n",
    "    # print(\"\\n Input: \\n\", input)\n",
    "\n",
    "    output = input[:, :4, 0]\n",
    "    dernomalized_output = train_dataset.dernormalize(output)\n",
    "    # print(\"\\n dernomalized_output: \\n\", dernomalized_output)\n",
    "    # print(dernomalized_output[0, :])\n",
    "    # print(\"\\n ground_truth normalized: \\n\", ground_truth)\n",
    "    print(\"\\n ground_truth denormalized: \\n\", train_dataset.dernormalize(ground_truth))\n",
    "\n",
    "    break\n",
    "for batch in test_loader:\n",
    "    input, ground_truth = batch\n",
    "    # print(\"\\n Input: \\n\", input)\n",
    "\n",
    "    output = input[:, :4, 0]\n",
    "    dernomalized_output = test_dataset.dernormalize(output)\n",
    "    # print(\"\\n dernomalized_output: \\n\", dernomalized_output)\n",
    "    # print(dernomalized_output[0, :])\n",
    "    # print(\"\\n ground_truth normalized: \\n\", ground_truth)\n",
    "    print(\"\\n ground_truth denormalized: \\n\", test_dataset.dernormalize(ground_truth))\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.save_scaler()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trail",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
